{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NQG with Attention.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Uz4FpyHjt-P_",
        "vDsRMWZExdXn",
        "OmFQgD1qxkk2",
        "X3w6fCrCxm_f"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJojn4Ojt56G",
        "colab_type": "text"
      },
      "source": [
        "# Neural Question Generation using Attention.\n",
        "**Updating**\n",
        "* Masking - For the model to ignore certain values\n",
        "* Packed Padded Sequences - RNN to skip padded sequences\n",
        "### And\n",
        "- Interference is taken <> Given a sentence => Question is Generated\n",
        "- BLEU Scores for evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz4FpyHjt-P_",
        "colab_type": "text"
      },
      "source": [
        "# Step-1 : Initial Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaLH6gzVwW2r",
        "colab_type": "text"
      },
      "source": [
        "## Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqOOaoGXwoMQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f8007b0e-1a65-47bd-c968-0949f00ce9af"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMtw-BfAwVBV",
        "colab_type": "text"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J69Cba4Mv4Ky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import torch.nn as nn\n",
        "from torchtext.data import  Field, BucketIterator, TabularDataset\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import spacy\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrNaunvA3RtY",
        "colab_type": "text"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSMgmD943Q5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !python -m spacy download en\n",
        "spacy_en = spacy.load('en')\n",
        "\n",
        "DEVICE = torch.device ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "DATASET_BASE_PATH = '/content/drive/My Drive/csv_for_nqg'\n",
        "TRAIN_FILENAME =  'train-v2.csv'\n",
        "VALID_FILENAME = 'dev-v2.csv'\n",
        "train_df = pd.read_csv(os.path.join(DATASET_BASE_PATH, TRAIN_FILENAME))\n",
        "valid_df = pd.read_csv(os.path.join(DATASET_BASE_PATH, VALID_FILENAME))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruFbEYmr4PMD",
        "colab_type": "text"
      },
      "source": [
        "## Setting Seeds for deterministic Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx0ajJYN4PUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL3_Bp5lxRqW",
        "colab_type": "text"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ssMokBu3GPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizer(text):\n",
        "  return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhnMyvUUxXRi",
        "colab_type": "text"
      },
      "source": [
        "# Step-2 : Preparing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf7XTM7Q4xpi",
        "colab_type": "text"
      },
      "source": [
        "## Analysing dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO0PijvR4xyZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "1d095399-bccb-4567-9fb7-8336fdafd7de"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>sentence</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>sent_ans</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "      <td>Beyonce would take a break from music in which...</td>\n",
              "      <td>2010</td>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "      <td>Which year did Beyonce and her father part bus...</td>\n",
              "      <td>2010</td>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "      <td>Beyoncé 's musical break lasted nine months an...</td>\n",
              "      <td>Which famous landmark did Beyonce see in China ?</td>\n",
              "      <td>the Great Wall of China</td>\n",
              "      <td>Beyoncé 's musical break lasted nine months an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "      <td>In what year did Beyonce have her hiatus ?</td>\n",
              "      <td>2010</td>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "      <td>Who inspired this hiatus ?</td>\n",
              "      <td>her mother</td>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             context  ...                                           sent_ans\n",
              "0  Beyoncé announced a hiatus from her music care...  ...  Beyoncé announced a hiatus from her music care...\n",
              "1  Beyoncé announced a hiatus from her music care...  ...  Beyoncé announced a hiatus from her music care...\n",
              "2  Beyoncé announced a hiatus from her music care...  ...  Beyoncé 's musical break lasted nine months an...\n",
              "3  Beyoncé announced a hiatus from her music care...  ...  Beyoncé announced a hiatus from her music care...\n",
              "4  Beyoncé announced a hiatus from her music care...  ...  Beyoncé announced a hiatus from her music care...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HePxLi3xz4b",
        "colab_type": "text"
      },
      "source": [
        "## Creating Fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU7qi1Trx0ae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_FIELD = Field(sequential = True,\n",
        "                          init_token = '<sos>',\n",
        "                          tokenize = tokenizer,\n",
        "                          lower = True,\n",
        "                          eos_token = '<eos>',\n",
        "                          # include_lengths = True,\n",
        "                          pad_token = '<pad>'\n",
        "                          )\n",
        "\n",
        "VALID_FIELD = Field(sequential = True,\n",
        "                          init_token = '<sos>',\n",
        "                          tokenize = tokenizer,\n",
        "                          lower = True,\n",
        "                          eos_token = '<eos>',\n",
        "                          pad_token = '<pad>'\n",
        "                          )\n",
        "\n",
        "TRAIN_VAL_FIELDS = [('context', None),\n",
        "                    ('sentence', None),\n",
        "                    ('question', VALID_FIELD),\n",
        "                    ('answer', None),\n",
        "                    ('sent_ans', TRAIN_FIELD)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp8olLEKx12N",
        "colab_type": "text"
      },
      "source": [
        "## Creating Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIK9F-xwx3db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, valid_data = TabularDataset.splits(path=DATASET_BASE_PATH,      \n",
        "                                          format='csv',\n",
        "                                          train=TRAIN_FILENAME,\n",
        "                                          validation=VALID_FILENAME,\n",
        "                                          fields=TRAIN_VAL_FIELDS,\n",
        "                                          skip_header=True\n",
        "                                          )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWfVMA5Y8wat",
        "colab_type": "text"
      },
      "source": [
        "## Building Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCLFvzvf8wVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_FIELD.build_vocab(train_data, valid_data, min_freq=2)\n",
        "VALID_FIELD.build_vocab(train_data, valid_data, min_freq=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALNnBnrqx3zL",
        "colab_type": "text"
      },
      "source": [
        "## Creating DataIterators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drklrPxTx4Gc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BATCH_SIZE, VALID_BATCH_SIZE = 128, 128\n",
        "\n",
        "train_iter, valid_iter = BucketIterator.splits(datasets = (train_data, valid_data),\n",
        "                                               batch_sizes = (TRAIN_BATCH_SIZE, VALID_BATCH_SIZE),\n",
        "                                               sort_within_batch = True,\n",
        "                                               sort_key = lambda x : len(x.sent_ans),\n",
        "                                               device = DEVICE\n",
        "                                               )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiEYscqVyDTy",
        "colab_type": "text"
      },
      "source": [
        "## Checking Datasets, Iterators and Fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXwo6z2Q_KcH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "305bcf96-3b4d-4ad1-e919-9a148d8cced7"
      },
      "source": [
        "print(f\"Lenght of train_data is {len(train_data)}, valid_data is {len(valid_data)}\")\n",
        "print(f\"Type of train_data is {type(train_data)}, valid_data is {type(valid_data)}\")\n",
        "print(train_data.fields.items())\n",
        "example = train_data[0]\n",
        "print(type(example))\n",
        "print(example.sent_ans, example.question)\n",
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lenght of train_data is 18222, valid_data is 871\n",
            "Type of train_data is <class 'torchtext.data.dataset.TabularDataset'>, valid_data is <class 'torchtext.data.dataset.TabularDataset'>\n",
            "dict_items([('context', None), ('sentence', None), ('question', <torchtext.data.field.Field object at 0x7ff27ee027b8>), ('answer', None), ('sent_ans', <torchtext.data.field.Field object at 0x7ff27ee02710>)])\n",
            "<class 'torchtext.data.example.Example'>\n",
            "['beyoncé', 'announced', 'a', 'hiatus', 'from', 'her', 'music', 'career', 'in', 'january', '2010', ',', 'heeding', 'her', 'mother', \"'s\", 'advice', ',', '\"', 'to', 'live', 'life', ',', 'to', 'be', 'inspired', 'by', 'things', 'again', '\"', '.', 'answer', '2010'] ['beyonce', 'would', 'take', 'a', 'break', 'from', 'music', 'in', 'which', 'year', '?']\n",
            "{'question': ['beyonce', 'would', 'take', 'a', 'break', 'from', 'music', 'in', 'which', 'year', '?'], 'sent_ans': ['beyoncé', 'announced', 'a', 'hiatus', 'from', 'her', 'music', 'career', 'in', 'january', '2010', ',', 'heeding', 'her', 'mother', \"'s\", 'advice', ',', '\"', 'to', 'live', 'life', ',', 'to', 'be', 'inspired', 'by', 'things', 'again', '\"', '.', 'answer', '2010']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI5UC5ayyHeT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "4d5a0d53-25e0-4f5f-b140-17456054aeaa"
      },
      "source": [
        "print(f\"Size of batch  of the train_data is {len(train_iter)} and valid_data is {len(valid_iter)}\")\n",
        "batch = next(iter(train_iter))\n",
        "print(type(batch))\n",
        "print(batch.sent_ans, batch.sent_ans[0].shape)\n",
        "print(batch.question, batch.question.shape)\n",
        "print(batch.dataset.fields)\n",
        "print(TRAIN_FIELD.vocab.stoi[TRAIN_FIELD.pad_token], TRAIN_FIELD.vocab.itos[2])\n",
        "print(TRAIN_FIELD.pad_token, TRAIN_FIELD.pad_first)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of batch  of the train_data is 143 and valid_data is 7\n",
            "<class 'torchtext.data.batch.Batch'>\n",
            "tensor([[    2,     2,     2,  ...,     2,     2,     2],\n",
            "        [11078,     4,    10,  ...,    10,    10,   911],\n",
            "        [  549,  1897,    65,  ...,   198,   198,  7229],\n",
            "        ...,\n",
            "        [   40,    89,     8,  ...,     8,     8,   742],\n",
            "        [13561,  1259,  7752,  ...,   278,   198,   234],\n",
            "        [    3,     3,     3,  ...,     3,     3,     3]], device='cuda:0') torch.Size([128])\n",
            "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  77,    6,    8,  ...,    8,    8,    0],\n",
            "        [  33,  690,  163,  ...,    6,    6, 4932],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0') torch.Size([22, 128])\n",
            "{'context': None, 'sentence': None, 'question': <torchtext.data.field.Field object at 0x7ff27ee027b8>, 'answer': None, 'sent_ans': <torchtext.data.field.Field object at 0x7ff27ee02710>}\n",
            "1 <sos>\n",
            "<pad> False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d47XLW0xaWC",
        "colab_type": "text"
      },
      "source": [
        "# Step-3 : Building Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyiIPQjRyJDO",
        "colab_type": "text"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-Oid7M2yJz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_dim, embed_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "    super(Encoder, self).__init__()\n",
        "    \n",
        "    self.embedding = nn.Embedding(input_dim, embed_dim)\n",
        "    self.rnn = nn.GRU(embed_dim, enc_hid_dim, bidirectional = True)\n",
        "    self.fc = nn.Linear(enc_hid_dim*2, dec_hid_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, src):\n",
        "    # src = [src_len, batch_size]\n",
        "    embedded = self.embedding(src)\n",
        "    # embedded = [src_len, batch_size, embed_dim]\n",
        "\n",
        "    output, hidden = self.rnn(embedded)\n",
        "    # output = [src_len, batch_size, n_direction*hid_dim]\n",
        "    # hidden = [num_dir * num*layers, batch_size, hid_dim]\n",
        "\n",
        "    #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
        "    #outputs are always from the last layer\n",
        "\n",
        "    # hidden[-2, :, :] is the last layer of the forward RNN\n",
        "    # hidden[-1, :, :] is the last layer of the backward RNN\n",
        "\n",
        "    hidden = torch.tanh(self.fc(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)))\n",
        "    # hidden = [batch_size, dec_hid_dim]\n",
        "    # output = [src_len, batch_size, 2*enc_hid_dim]\n",
        "    return output, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmbYPmJtyK9F",
        "colab_type": "text"
      },
      "source": [
        "## Attention\n",
        "\n",
        "* Attention will take in the previous hidden state of the decoder and all of the stacked forward and backward hidden states from the encoder,  𝐻 . The layer will output an attention vector,  𝑎𝑡 , that is the length of the source sentence, each element is between 0 and 1 and the entire vector sums to 1.\n",
        "* First, we calculate the energy between the previous decoder hidden state and the encoder hidden states. As our encoder hidden states are a sequence of  𝑇  tensors, and our previous decoder hidden state is a single tensor, the first thing we do is repeat the previous decoder hidden state  𝑇  times.\n",
        "* We currently have a [dec hid dim, src len] tensor for each example in the batch. We want this to be [src len] for each example in the batch as the attention should be over the length of the source sentence. This is achieved by multiplying the energy by a [1, dec hid dim] tensor,  𝑣 .\n",
        "* Finally, we ensure the attention vector fits the constraints of having all elements between 0 and 1 and the vector summing to 1 by passing it through a  softmax  layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3QRegRJyLsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "    super(Attention, self).__init__()\n",
        "    \n",
        "    self.attn = nn.Linear((enc_hid_dim*2)+dec_hid_dim, dec_hid_dim)\n",
        "    self.v = nn.Linear(dec_hid_dim, 1, bias=False)\n",
        "\n",
        "  def forward(self, enc_outputs, hidden):\n",
        "    # enc_outputs = [src_len, batch_size, 2*enc_hid_dim]\n",
        "    # hidden = [batch_size, dec_hid_dim]\n",
        "\n",
        "    batch_size = enc_outputs.shape[1]\n",
        "    src_len = enc_outputs.shape[0]\n",
        "    hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "    enc_outputs = enc_outputs.permute(1, 0, 2)\n",
        "\n",
        "    # hidden = [batch_size, src_len, dec_hid_dim]\n",
        "    # enc_outputs = [batch_size, src_len, enc_hid_dim*2]\n",
        "    combined = torch.cat((hidden, enc_outputs), dim=2)\n",
        "    energy = torch.tanh(self.attn(combined))\n",
        "\n",
        "    # energy = [batch_size, src_len, dec_hid_dim]\n",
        "    attention = self.v(energy).squeeze(2)\n",
        "\n",
        "    # attention = [batch_size, src_len]\n",
        "\n",
        "    return F.softmax(attention, dim=1)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwMMpKrvyMEd",
        "colab_type": "text"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCHb1ynGyMc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, output_dim, embed_dim, enc_hid_dim, dec_hid_dim, attention, dropout):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.output_dim = output_dim\n",
        "\n",
        "    self.embedding = nn.Embedding(output_dim, embed_dim)\n",
        "    self.attention = attention\n",
        "    self.rnn = nn.GRU((enc_hid_dim*2) + embed_dim, dec_hid_dim)\n",
        "    self.fc = nn.Linear(((enc_hid_dim*2) + dec_hid_dim + embed_dim), output_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, input, hidden, encoder_outputs):\n",
        "    # input = [batch_size]\n",
        "    # hidden = [batch_size, dec_hid_dim]\n",
        "    # encoder_outputs = [src_len, batch_size, 2*enc_hid_dim]\n",
        "    input = input.unsqueeze(0)\n",
        "    # input = [1, batch_size]\n",
        "    embedded = self.dropout(self.embedding(input))\n",
        "    # embedded = [1, batch_size, embed_dim]\n",
        "\n",
        "    a = self.attention(encoder_outputs, hidden)\n",
        "    # attention = [batch_size, src_len]\n",
        "    a = a.unsqueeze(1)\n",
        "    # attention = [batch_size, 1, src_len]\n",
        "    encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "    # encoder_outputs = [batch_size, src_len, 2*enc_hid_dim]\n",
        "\n",
        "    weighted = torch.bmm(a, encoder_outputs)\n",
        "    # weighted = [batch_size, 1, enc_hid_dim*2]\n",
        "    weighted = weighted.permute(1, 0, 2)\n",
        "    # weighted = [1, batch_size, enc_hid_dim*2]\n",
        "\n",
        "    rnn_input = torch.cat((weighted, embedded), dim=2)\n",
        "\n",
        "    output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "\n",
        "    #output = [1, batch size, dec hid dim]\n",
        "    #hidden = [1, batch size, dec hid dim]\n",
        "    \n",
        "    assert (output==hidden).all()\n",
        "    embedded = embedded.squeeze(0)\n",
        "    output = output.squeeze(0)\n",
        "    weighted = weighted.squeeze(0)\n",
        "    \n",
        "    prediction = self.fc(torch.cat((output, weighted, embedded), dim = 1))\n",
        "    \n",
        "    #prediction = [batch size, output dim]\n",
        "    \n",
        "    return prediction, hidden.squeeze(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6KZN74-yRsW",
        "colab_type": "text"
      },
      "source": [
        "## Seq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6-5suwuyTWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
        "        \n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "                \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden state and all encoder hidden states\n",
        "            #receive output tensor (predictions) and new hidden state\n",
        "            output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDsRMWZExdXn",
        "colab_type": "text"
      },
      "source": [
        "# Step-4 : Train, Test and Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE8XZCI0yoMw",
        "colab_type": "text"
      },
      "source": [
        "## Train Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CSJ16W7yoqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.sent_ans\n",
        "        trg = batch.question\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, trg)\n",
        "        \n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK_0YejuypFY",
        "colab_type": "text"
      },
      "source": [
        "## Validation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv69RBz5ypV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.sent_ans\n",
        "            trg = batch.question\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9CdXhrgypmo",
        "colab_type": "text"
      },
      "source": [
        "## Time Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfeUFZ5Xyp8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmFQgD1qxkk2",
        "colab_type": "text"
      },
      "source": [
        "# Step-5 : Initialize models & Start Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjmsgLEDy7Qv",
        "colab_type": "text"
      },
      "source": [
        "## Parameters and Creating Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9x9FMGDyxAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(TRAIN_FIELD.vocab)\n",
        "OUTPUT_DIM = len(VALID_FIELD.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "ENC_HID_DIM = 512\n",
        "DEC_HID_DIM = 512\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, attn, DEC_DROPOUT)\n",
        "\n",
        "model = Seq2Seq(enc, dec, DEVICE).to(DEVICE)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "TRG_PAD_IDX = TRAIN_FIELD.vocab.stoi[TRAIN_FIELD.pad_token]\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L94ndAZxywve",
        "colab_type": "text"
      },
      "source": [
        "## Weights Initialization and Count Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jzgkfhrny9Gj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "8dbb3452-7262-443b-aa9f-99e4e1802c1f"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "            \n",
        "model.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 30,788,347 trainable parameters\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(23462, 256)\n",
              "    (rnn): GRU(256, 512, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(8955, 256)\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
              "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "    )\n",
              "    (rnn): GRU(1280, 512)\n",
              "    (fc): Linear(in_features=1792, out_features=8955, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C30_LSF9y9Y8",
        "colab_type": "text"
      },
      "source": [
        "## Start Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr6GVDmsy9tp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "72c0ad1a-363d-44e0-ad87-ca9d315231b1"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iter, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iter, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut3-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 1m 44s\n",
            "\tTrain Loss: 5.960 | Train PPL: 387.534\n",
            "\t Val. Loss: 6.016 |  Val. PPL: 409.930\n",
            "Epoch: 02 | Time: 1m 44s\n",
            "\tTrain Loss: 5.265 | Train PPL: 193.396\n",
            "\t Val. Loss: 5.966 |  Val. PPL: 390.027\n",
            "Epoch: 03 | Time: 1m 43s\n",
            "\tTrain Loss: 5.011 | Train PPL: 150.124\n",
            "\t Val. Loss: 5.978 |  Val. PPL: 394.501\n",
            "Epoch: 04 | Time: 1m 43s\n",
            "\tTrain Loss: 4.762 | Train PPL: 116.925\n",
            "\t Val. Loss: 6.023 |  Val. PPL: 412.640\n",
            "Epoch: 05 | Time: 1m 44s\n",
            "\tTrain Loss: 4.543 | Train PPL:  93.985\n",
            "\t Val. Loss: 6.027 |  Val. PPL: 414.474\n",
            "Epoch: 06 | Time: 1m 45s\n",
            "\tTrain Loss: 4.273 | Train PPL:  71.763\n",
            "\t Val. Loss: 6.137 |  Val. PPL: 462.549\n",
            "Epoch: 07 | Time: 1m 44s\n",
            "\tTrain Loss: 3.953 | Train PPL:  52.076\n",
            "\t Val. Loss: 6.291 |  Val. PPL: 539.734\n",
            "Epoch: 08 | Time: 1m 44s\n",
            "\tTrain Loss: 3.640 | Train PPL:  38.109\n",
            "\t Val. Loss: 6.345 |  Val. PPL: 569.440\n",
            "Epoch: 09 | Time: 1m 44s\n",
            "\tTrain Loss: 3.333 | Train PPL:  28.027\n",
            "\t Val. Loss: 6.510 |  Val. PPL: 671.944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3w6fCrCxm_f",
        "colab_type": "text"
      },
      "source": [
        "# Step-6 : Inference and Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeDIWPQ6zE-7",
        "colab_type": "text"
      },
      "source": [
        "## Calulcating Validation loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSq6ePDIzFPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(torch.load('tut3-model.pt'))\n",
        "\n",
        "test_loss = evaluate(model, valid_iter, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}