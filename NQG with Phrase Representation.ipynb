{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NQG with phrase representation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ynCOQ1TZmck",
        "colab_type": "text"
      },
      "source": [
        "# Neural Seq2Seq Question Generation with Phrase Representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uczx5415aut5",
        "colab_type": "text"
      },
      "source": [
        "# Mounting Drive for Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pt9avlJazUj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c84a53b6-db4e-4bb3-a363-c83e3416bc80"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nggGgZczbTiG",
        "colab_type": "text"
      },
      "source": [
        "# Step 1: Initial Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4KFUQ86cqUd",
        "colab_type": "text"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN8TW2ombnSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import spacy\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "from torchtext.data import Field, TabularDataset, BucketIterator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLlTmZYccgIw",
        "colab_type": "text"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kqom9w3ubqPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !python -m spacy download en     ## If tokenization error try to update the spacyt package\n",
        "\n",
        "DATASET_BASE_PATH = '/content/drive/My Drive/csv_for_nqg'\n",
        "TRAIN_FILENAME =  'train-v2.csv'\n",
        "VALID_FILENAME = 'dev-v2.csv'\n",
        "train_df = pd.read_csv(os.path.join(DATASET_BASE_PATH, TRAIN_FILENAME))\n",
        "valid_df = pd.read_csv(os.path.join(DATASET_BASE_PATH, VALID_FILENAME))\n",
        "\n",
        "spacy_en = spacy.load('en')\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QNBnhADcuKy",
        "colab_type": "text"
      },
      "source": [
        "## Settting up seed for detereministic results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFvSgHF-ctLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnndeterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq1xhECJdPr-",
        "colab_type": "text"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFqIYenadaEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizer(text):\n",
        "  '''\n",
        "  Function for tokenizing with spacy english model\n",
        "  '''\n",
        "  return  [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvW-vebydcM3",
        "colab_type": "text"
      },
      "source": [
        "# Step-2 : Preparing Data\n",
        "* Fields\n",
        "* Dataset\n",
        "* Iterators\n",
        "* Build Vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAMGW4KKdlvB",
        "colab_type": "text"
      },
      "source": [
        "## Check data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlNxoHuCdqQh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "c7c80d73-e5ee-40e7-96f4-f41602e94b9a"
      },
      "source": [
        "print(train_df.shape)\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18222, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>sentence</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>sent_ans</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "      <td>Beyonce would take a break from music in which...</td>\n",
              "      <td>2010</td>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "      <td>Which year did Beyonce and her father part bus...</td>\n",
              "      <td>2010</td>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "      <td>Beyoncé 's musical break lasted nine months an...</td>\n",
              "      <td>Which famous landmark did Beyonce see in China ?</td>\n",
              "      <td>the Great Wall of China</td>\n",
              "      <td>Beyoncé 's musical break lasted nine months an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "      <td>In what year did Beyonce have her hiatus ?</td>\n",
              "      <td>2010</td>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "      <td>Who inspired this hiatus ?</td>\n",
              "      <td>her mother</td>\n",
              "      <td>Beyoncé announced a hiatus from her music care...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             context  ...                                           sent_ans\n",
              "0  Beyoncé announced a hiatus from her music care...  ...  Beyoncé announced a hiatus from her music care...\n",
              "1  Beyoncé announced a hiatus from her music care...  ...  Beyoncé announced a hiatus from her music care...\n",
              "2  Beyoncé announced a hiatus from her music care...  ...  Beyoncé 's musical break lasted nine months an...\n",
              "3  Beyoncé announced a hiatus from her music care...  ...  Beyoncé announced a hiatus from her music care...\n",
              "4  Beyoncé announced a hiatus from her music care...  ...  Beyoncé announced a hiatus from her music care...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDy26_-Md3Nw",
        "colab_type": "text"
      },
      "source": [
        "## Creating Fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFy7KBvhdrjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FIELD = Field(sequential=True,\n",
        "                   tokenize=tokenizer,\n",
        "                   init_token='<sos>',\n",
        "                   eos_token='<eos>',\n",
        "                   lower=True)\n",
        "\n",
        "TRAIN_VALID_FIELDS = [('context', None), ## For this phase of the project we are not using context, So no field assigned\n",
        "                    ('sentence', None), ## Sentence is one of the column of interest and preprocessing is needed so Field is also needed\n",
        "                    ('question', FIELD), ## Question is another columnd of interest\n",
        "                    ('answer', None), ## We will not be using answer at this phase\n",
        "                    ('sent_ans', FIELD) ## Not now\n",
        "                    ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJg1N2E-d1Jg",
        "colab_type": "text"
      },
      "source": [
        "## Creating datasets with Fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y82yRe36eC3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, valid_data = TabularDataset.splits(path=DATASET_BASE_PATH,\n",
        "                                        format='csv',\n",
        "                                        train = TRAIN_FILENAME,\n",
        "                                        validation = VALID_FILENAME,\n",
        "                                        fields = TRAIN_VALID_FIELDS,\n",
        "                                        skip_header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCOfjw2teFYu",
        "colab_type": "text"
      },
      "source": [
        "## Analysing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G593zhHHeMfy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "fda7cfa6-b2fe-448b-a9d8-1ef8431baaa8"
      },
      "source": [
        "print(f\"Type of train data => {type(train_data)} and valid data => {type(valid_data)}\")\n",
        "print(f\"Length of train data => {len(train_data)} and valid data => {len(valid_data)}\")\n",
        "print(train_data.fields.items())\n",
        "example = train_data[0]\n",
        "print(type(example))\n",
        "# print(example.sentence, example.question)\n",
        "print(example.sent_ans, example.question)\n",
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type of train data => <class 'torchtext.data.dataset.TabularDataset'> and valid data => <class 'torchtext.data.dataset.TabularDataset'>\n",
            "Length of train data => 18222 and valid data => 871\n",
            "dict_items([('context', None), ('sentence', None), ('question', <torchtext.data.field.Field object at 0x7f105c4dfa58>), ('answer', None), ('sent_ans', <torchtext.data.field.Field object at 0x7f105c4dfa58>)])\n",
            "<class 'torchtext.data.example.Example'>\n",
            "['beyoncé', 'announced', 'a', 'hiatus', 'from', 'her', 'music', 'career', 'in', 'january', '2010', ',', 'heeding', 'her', 'mother', \"'s\", 'advice', ',', '\"', 'to', 'live', 'life', ',', 'to', 'be', 'inspired', 'by', 'things', 'again', '\"', '.', 'answer', '2010'] ['beyonce', 'would', 'take', 'a', 'break', 'from', 'music', 'in', 'which', 'year', '?']\n",
            "{'question': ['beyonce', 'would', 'take', 'a', 'break', 'from', 'music', 'in', 'which', 'year', '?'], 'sent_ans': ['beyoncé', 'announced', 'a', 'hiatus', 'from', 'her', 'music', 'career', 'in', 'january', '2010', ',', 'heeding', 'her', 'mother', \"'s\", 'advice', ',', '\"', 'to', 'live', 'life', ',', 'to', 'be', 'inspired', 'by', 'things', 'again', '\"', '.', 'answer', '2010']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqidI-j4eN9P",
        "colab_type": "text"
      },
      "source": [
        "## Building Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok5cOFZGeVM-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8a2b0c83-0cba-429c-ee30-af64e67a1e1b"
      },
      "source": [
        "FIELD.build_vocab(train_data, valid_data, min_freq=2)\n",
        "\n",
        "print(f\"Total length of train vocabulary is {len(FIELD.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total length of train vocabulary is 24953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af7-Sm0aeWoU",
        "colab_type": "text"
      },
      "source": [
        "## Data Iterator for batches of data\n",
        "\n",
        "Takes care about padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNgKceqJe9ka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator, valid_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    # sort_key = lambda x: len(x.sentence),\n",
        "    sort_key = lambda x: len(x.sent_ans),\n",
        "    device = DEVICE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ6udLFQe_4s",
        "colab_type": "text"
      },
      "source": [
        "## Understanding Iterator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxjdaFMgfHBK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "a68de30d-5896-4f00-d6be-cd710c5b18b1"
      },
      "source": [
        "print(f\"Size of the train and valid iterators =>>> {len(train_iterator)}, {len(valid_iterator)}\")\n",
        "batch = next(iter(train_iterator))\n",
        "print(type(batch))\n",
        "# print(batch.sentence, batch.sentence.shape)   \n",
        "print(batch.sent_ans, batch.sent_ans.shape)\n",
        "print(batch.question, batch.question.shape)\n",
        "print(batch.dataset.fields)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of the train and valid iterators =>>> 143, 7\n",
            "<class 'torchtext.data.batch.Batch'>\n",
            "tensor([[    2,     2,     2,  ...,     2,     2,     2],\n",
            "        [    7,  1011,     4,  ...,     7,    79, 13501],\n",
            "        [  823,   315,   130,  ...,  7532,  2290,  1001],\n",
            "        ...,\n",
            "        [    1,     1,     1,  ...,     1,     1,     1],\n",
            "        [    1,     1,     1,  ...,     1,     1,     1],\n",
            "        [    1,     1,     1,  ...,     1,     1,     1]], device='cuda:0') torch.Size([86, 128])\n",
            "tensor([[    2,     2,     2,  ...,     2,     2,     2],\n",
            "        [   13,    19,   507,  ...,    13, 17868,    13],\n",
            "        [   16,    13,  3222,  ...,   112,  2655,    15],\n",
            "        ...,\n",
            "        [    1,   394,     1,  ...,    10,     1,     1],\n",
            "        [    1,    10,     1,  ...,     3,     1,     1],\n",
            "        [    1,     3,     1,  ...,     1,     1,     1]], device='cuda:0') torch.Size([21, 128])\n",
            "{'context': None, 'sentence': None, 'question': <torchtext.data.field.Field object at 0x7f105c4dfa58>, 'answer': None, 'sent_ans': <torchtext.data.field.Field object at 0x7f105c4dfa58>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T9OmpKsfIhd",
        "colab_type": "text"
      },
      "source": [
        "### Note:\n",
        "\n",
        "* You can see that BucketIterator returns a batch object instead of sentence tensors and question tensors\n",
        "* Also we can't iterate through batch object\n",
        "* We can overcome this problem by writing a wrapper around Iterator object which will return required data or we can write some extra code for the same. In this tutorial we will move with the second approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW1rVaFSgwbL",
        "colab_type": "text"
      },
      "source": [
        "# Step-3 : Building Model\n",
        "\n",
        "We are going to use phrase representation.\n",
        "* **Why?**\n",
        "  -We have seen a difficulty of decoder RNN to compress all the information of context vector and also prevviously predicted in a vector.\n",
        "* **What is phrase representation?**\n",
        "- We are giving the context and also embedded previous input for every linear layer and also each RNN inputs such that since we are pro.\n",
        "\n",
        "Compared to the previous notebook we only need to add changes to the decoder model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JdWYDCQg_r_",
        "colab_type": "text"
      },
      "source": [
        "## Encoder Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuQq6DULmrA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim) #no dropout as only one layer!\n",
        "        \n",
        "        self.rnn = nn.GRU(emb_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "        \n",
        "        outputs, hidden = self.rnn(embedded) #no cell state!\n",
        "        \n",
        "        #outputs = [src len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #outputs are always from the top hidden layer\n",
        "        \n",
        "        return hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_y5ly1imufx",
        "colab_type": "text"
      },
      "source": [
        "## Decoder Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_DZbMGMmwrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        self.output_dim = output_dim\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU(emb_dim + hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_out = nn.Linear(emb_dim + hid_dim * 2, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, context):\n",
        "        \n",
        "        #input = [batch size]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #context = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #n layers and n directions in the decoder will both always be 1, therefore:\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        #context = [1, batch size, hid dim]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "                \n",
        "        emb_con = torch.cat((embedded, context), dim = 2)\n",
        "            \n",
        "        #emb_con = [1, batch size, emb dim + hid dim]\n",
        "            \n",
        "        output, hidden = self.rnn(emb_con, hidden)\n",
        "        \n",
        "        #output = [seq len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #seq len, n layers and n directions will always be 1 in the decoder, therefore:\n",
        "        #output = [1, batch size, hid dim]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        \n",
        "        output = torch.cat((embedded.squeeze(0), hidden.squeeze(0), context.squeeze(0)), \n",
        "                           dim = 1)\n",
        "        \n",
        "        #output = [batch size, emb dim + hid dim * 2]\n",
        "        \n",
        "        prediction = self.fc_out(output)\n",
        "        \n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWRxcInomzbo",
        "colab_type": "text"
      },
      "source": [
        "## Seq2Seq Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEVgO68Zm85D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        \n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #last hidden state of the encoder is the context\n",
        "        context = self.encoder(src)\n",
        "        \n",
        "        #context also used as the initial hidden state of the decoder\n",
        "        hidden = context\n",
        "        \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden state and the context state\n",
        "            #receive output tensor (predictions) and new hidden state\n",
        "            output, hidden = self.decoder(input, hidden, context)\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQL07XsUm9iQ",
        "colab_type": "text"
      },
      "source": [
        "# Step-4 : Setting up parameters and other functions required for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm-FOfKUnfH1",
        "colab_type": "text"
      },
      "source": [
        "## Setting model and parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6qzXxOXnPmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(FIELD.vocab)\n",
        "OUTPUT_DIM = len(FIELD.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, DEC_DROPOUT)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKTIHEfNncAg",
        "colab_type": "text"
      },
      "source": [
        "## Initializing weights and counting parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmvtxC5dnpgn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "74472075-79a2-40ac-e0f1-37bd0684220c"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        \n",
        "model.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(24953, 256)\n",
              "    (rnn): GRU(256, 512)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(24953, 256)\n",
              "    (rnn): GRU(768, 512)\n",
              "    (fc_out): Linear(in_features=1280, out_features=24953, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eNHboz2nq5E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "30a18515-3b5d-4b19-e5a3-2d7e5c6eeb25"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 47,892,601 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z6n2qChnyVM",
        "colab_type": "text"
      },
      "source": [
        "## Optimizer and loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQT71ZoVn4PX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "PAD_IDX = FIELD.vocab.stoi[FIELD.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWl9m--hn-_f",
        "colab_type": "text"
      },
      "source": [
        "## Time function for evaluating time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Czx9s8XSoBQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "  total_time = end_time - start_time\n",
        "  epoch_mins = int((total_time)/60)\n",
        "  epoch_secs = int(total_time - (epoch_mins*60))\n",
        "  return epoch_mins, epoch_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_ekRk31oEGn",
        "colab_type": "text"
      },
      "source": [
        "## Training and Evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KTJu_heofPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.sent_ans\n",
        "        # src = batch.sentence\n",
        "        trg = batch.question\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, trg)\n",
        "        \n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsUXiKQzohSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.sent_ans\n",
        "            # src = batch.sentence\n",
        "            trg = batch.question\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDHffKdAoijx",
        "colab_type": "text"
      },
      "source": [
        "## Start Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_mLpLvUozyd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ab862626-26e5-4912-90f6-8402dd453650"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 57s\n",
            "\tTrain Loss: 6.211 | Train PPL: 498.376\n",
            "\t Val. Loss: 6.348 |  Val. PPL: 571.330\n",
            "Epoch: 02 | Time: 0m 57s\n",
            "\tTrain Loss: 5.545 | Train PPL: 255.894\n",
            "\t Val. Loss: 6.425 |  Val. PPL: 616.815\n",
            "Epoch: 03 | Time: 0m 58s\n",
            "\tTrain Loss: 5.389 | Train PPL: 219.093\n",
            "\t Val. Loss: 6.469 |  Val. PPL: 644.576\n",
            "Epoch: 04 | Time: 0m 59s\n",
            "\tTrain Loss: 5.270 | Train PPL: 194.417\n",
            "\t Val. Loss: 6.527 |  Val. PPL: 683.455\n",
            "Epoch: 05 | Time: 0m 58s\n",
            "\tTrain Loss: 5.165 | Train PPL: 175.047\n",
            "\t Val. Loss: 6.612 |  Val. PPL: 744.259\n",
            "Epoch: 06 | Time: 0m 59s\n",
            "\tTrain Loss: 5.092 | Train PPL: 162.738\n",
            "\t Val. Loss: 6.583 |  Val. PPL: 722.838\n",
            "Epoch: 07 | Time: 0m 59s\n",
            "\tTrain Loss: 4.981 | Train PPL: 145.571\n",
            "\t Val. Loss: 6.664 |  Val. PPL: 783.996\n",
            "Epoch: 08 | Time: 0m 59s\n",
            "\tTrain Loss: 4.898 | Train PPL: 133.959\n",
            "\t Val. Loss: 6.760 |  Val. PPL: 862.946\n",
            "Epoch: 09 | Time: 0m 59s\n",
            "\tTrain Loss: 4.806 | Train PPL: 122.277\n",
            "\t Val. Loss: 6.679 |  Val. PPL: 795.670\n",
            "Epoch: 10 | Time: 0m 59s\n",
            "\tTrain Loss: 4.678 | Train PPL: 107.549\n",
            "\t Val. Loss: 6.911 |  Val. PPL: 1003.274\n",
            "Epoch: 11 | Time: 0m 59s\n",
            "\tTrain Loss: 4.660 | Train PPL: 105.596\n",
            "\t Val. Loss: 6.817 |  Val. PPL: 913.136\n",
            "Epoch: 12 | Time: 0m 59s\n",
            "\tTrain Loss: 4.535 | Train PPL:  93.265\n",
            "\t Val. Loss: 6.908 |  Val. PPL: 1000.375\n",
            "Epoch: 13 | Time: 0m 59s\n",
            "\tTrain Loss: 4.469 | Train PPL:  87.229\n",
            "\t Val. Loss: 6.930 |  Val. PPL: 1022.387\n",
            "Epoch: 14 | Time: 0m 59s\n",
            "\tTrain Loss: 4.425 | Train PPL:  83.524\n",
            "\t Val. Loss: 6.928 |  Val. PPL: 1020.632\n",
            "Epoch: 15 | Time: 0m 59s\n",
            "\tTrain Loss: 4.315 | Train PPL:  74.836\n",
            "\t Val. Loss: 6.952 |  Val. PPL: 1044.779\n",
            "Epoch: 16 | Time: 0m 59s\n",
            "\tTrain Loss: 4.101 | Train PPL:  60.403\n",
            "\t Val. Loss: 7.034 |  Val. PPL: 1134.661\n",
            "Epoch: 17 | Time: 0m 59s\n",
            "\tTrain Loss: 3.968 | Train PPL:  52.866\n",
            "\t Val. Loss: 7.034 |  Val. PPL: 1134.315\n",
            "Epoch: 18 | Time: 1m 0s\n",
            "\tTrain Loss: 3.700 | Train PPL:  40.454\n",
            "\t Val. Loss: 7.071 |  Val. PPL: 1176.944\n",
            "Epoch: 19 | Time: 0m 59s\n",
            "\tTrain Loss: 3.538 | Train PPL:  34.390\n",
            "\t Val. Loss: 7.158 |  Val. PPL: 1284.362\n",
            "Epoch: 20 | Time: 0m 59s\n",
            "\tTrain Loss: 3.276 | Train PPL:  26.469\n",
            "\t Val. Loss: 7.392 |  Val. PPL: 1622.881\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vi6EY3npo0zm",
        "colab_type": "text"
      },
      "source": [
        "# Results and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WW8Lz4EWpCPi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "41ec454d-adbf-4231-b6d7-69b3753b4196"
      },
      "source": [
        "model.load_state_dict(torch.load('model.pt'))\n",
        "\n",
        "test_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 6.348 | Test PPL: 571.330 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Kw1VrvLvxpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}